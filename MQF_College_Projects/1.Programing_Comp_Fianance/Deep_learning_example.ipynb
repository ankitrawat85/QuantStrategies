{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A deep learning price prediction model with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python libaries:\n",
    "- TensorFlow\n",
    "- keras\n",
    "- pandas\n",
    "- matplotlib\n",
    "- seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - matplolib\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/osx-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create -n tf_env python tensorflow numpy pandas matplolib seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m ipykernel install --user --name tf_env --display-name \"TF_ENV_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart browser and check Kernel drop down box - change to TF_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is optional.\n",
    "\n",
    "When the given Intrinio API key expires, the above codes will fail to fetch from the server.\n",
    "As a temporary workaround, load the dataset from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_independent_2013_2018')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close = pd.read_pickle('df_aapl_2013_2018')\n",
    "df_close.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df['2017':'2013']\n",
    "df_test = df[:'2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data = scaler.fit_transform(df_train.values)\n",
    "test_data = scaler.transform(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an artificial neural network with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Assembling the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "num_features = x_train.shape[1]\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, num_features])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_1, nl_2, nl_3, nl_4 = 512, 256, 128, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wi = tf.contrib.layers.variance_scaling_initializer(\n",
    "#     mode='FAN_AVG', uniform=True, factor=1)\n",
    "\n",
    "wi = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "    mode='fan_avg', distribution='uniform')\n",
    "\n",
    "\n",
    "zi = tf.zeros_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Hidden layers\n",
    "wt_hidden_1 = tf.Variable(wi([num_features, nl_1]))\n",
    "bias_hidden_1 = tf.Variable(zi([nl_1]))\n",
    "\n",
    "wt_hidden_2 = tf.Variable(wi([nl_1, nl_2]))\n",
    "bias_hidden_2 = tf.Variable(zi([nl_2]))\n",
    "\n",
    "wt_hidden_3 = tf.Variable(wi([nl_2, nl_3]))\n",
    "bias_hidden_3 = tf.Variable(zi([nl_3]))\n",
    "\n",
    "wt_hidden_4 = tf.Variable(wi([nl_3, nl_4]))\n",
    "bias_hidden_4 = tf.Variable(zi([nl_4]))\n",
    "\n",
    "# Output layer\n",
    "wt_out = tf.Variable(wi([nl_4, 1]))\n",
    "bias_out = tf.Variable(zi([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1 = tf.nn.relu(\n",
    "    tf.add(tf.matmul(x, wt_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(\n",
    "    tf.add(tf.matmul(hidden_1, wt_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(\n",
    "    tf.add(tf.matmul(hidden_2, wt_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(\n",
    "    tf.add(tf.matmul(hidden_3, wt_hidden_4), bias_hidden_4))\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, wt_out), bias_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.reduce_mean(tf.squared_difference(out, y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from numpy.random import permutation\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Shuffle the training data\n",
    "    shuffle_data = permutation(arange(len(y_train)))\n",
    "    x_train = x_train[shuffle_data]\n",
    "    y_train = y_train[shuffle_data]\n",
    "\n",
    "    # Mini-batch training\n",
    "    for i in range(len(y_train)//BATCH_SIZE):\n",
    "        start = i*BATCH_SIZE\n",
    "        batch_x = x_train[start:start+BATCH_SIZE]\n",
    "        batch_y = y_train[start:start+BATCH_SIZE]\n",
    "        session.run(optimizer, feed_dict={x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[predicted_values] = session.run(out, feed_dict={x: x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scaled_data = test_data.copy()\n",
    "predicted_scaled_data[:, -1] = predicted_values\n",
    "predicted_values = scaler.inverse_transform(predicted_scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_close[:'2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predicted_values[:, -1][::-1]\n",
    "actual = df_close[:'2018']['adj_close_price'].values[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Actual and predicted prices of AAPL 2018')\n",
    "plt.plot(actual, label='Actual')\n",
    "plt.plot(predictions, linestyle='dotted', label='Predicted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
