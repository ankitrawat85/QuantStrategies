{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "bikes = pd.read_csv('bike_sharing.csv')\n",
    "num_row = bikes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "train = np.random.choice([True, False], num_row, replace = True, p = [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will have several ways to organize our explanatory variables, to better compare these models, let's fix the instances for training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bikes['registered'].values\n",
    "y_train, y_test = y[train], y[~train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is 'casual', we split the entire column into training and test sets, according to the True/False flags in the array 'train'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "x1 = bikes[selected_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first construct a very simple regression model from numerical columns as listed above.<br/>\n",
    "In order to compare the coefficients to identify important columns, it is necessary to scale all columns to interval [0, 1] using <i>MinMaxScaler</i>.<br/>\n",
    "The three cells below listed three ways of doing min-max-scaling, please argue which way is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn import preprocessing\\nmin_max_scaler = preprocessing.MinMaxScaler()\\nx1 = min_max_scaler.fit_transform(x1)\\nx1_train, x1_test = x1[train,:], x1[~train,:]\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x1 = min_max_scaler.fit_transform(x1)\n",
    "x1_train, x1_test = x1[train,:], x1[~train,:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn import preprocessing\\nmin_max_scaler = preprocessing.MinMaxScaler()\\nx1_train, x1_test = x1[train,:], x1[~train,:]\\nx1_train = min_max_scaler.fit_transform(x1_train)\\nx1_test = min_max_scaler.fit_transform(x1_test)\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x1_train, x1_test = x1[train,:], x1[~train,:]\n",
    "x1_train = min_max_scaler.fit_transform(x1_train)\n",
    "x1_test = min_max_scaler.fit_transform(x1_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x1_train, x1_test = x1[train,:], x1[~train,:]\n",
    "x1_train = min_max_scaler.fit_transform(x1_train)\n",
    "x1_test = min_max_scaler.transform(x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1-2:\n",
    "The correct way is cell ____________.\n",
    "\n",
    "Third cell is right answer : \n",
    "#### split data and perform fit_tranform on test data and later perform  transform on train data. \n",
    "\n",
    "#### Justification : test data and training data should be independent and if we do normalization before splitting data then test data and training data will not be independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1.0 \t 0.3337561009257083\n",
      "R2 score: 0.3337561009257083\n",
      "season \t 0 48.552579241088914\n",
      "yr \t 1 67.47645896552172\n",
      "mnth \t 2 0.0\n",
      "hr \t 3 143.8534458356691\n",
      "holiday \t 4 -0.0\n",
      "weekday \t 5 0.0\n",
      "workingday \t 6 36.22018792716402\n",
      "weathersit \t 7 -0.0\n",
      "temp \t 8 141.3067102408608\n",
      "atemp \t 9 0.0\n",
      "hum \t 10 -110.50540041653332\n",
      "windspeed \t 11 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lasso = linear_model.Lasso(alpha = 1.0)\n",
    "lasso.fit(x1_train, y_train)\n",
    "print('alpha:', 1.0, '\\t', lasso.score(x1_test, y_test))\n",
    "print('R2 score:', lasso.score(x1_test, y_test))\n",
    "for i in range(len(selected_cols)):\n",
    "    print(selected_cols[i], '\\t',i,lasso.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ score is 0.33, and there are already 5 columns used for this model (columns with non-zero coefficients).<br/>\n",
    "Let's now decrease alpha to see if we can obtain a model with $R^2$ above 0.45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha: 1.0\n",
      "R2 score: 0.3337561009257083\n",
      "season \t 48.552579241088914\n",
      "yr \t 67.47645896552172\n",
      "mnth \t 0.0\n",
      "hr \t 143.8534458356691\n",
      "holiday \t -0.0\n",
      "weekday \t 0.0\n",
      "workingday \t 36.22018792716402\n",
      "weathersit \t -0.0\n",
      "temp \t 141.3067102408608\n",
      "atemp \t 0.0\n",
      "hum \t -110.50540041653332\n",
      "windspeed \t 0.0\n",
      "\n",
      "alpha: 0.5\n",
      "R2 score: 0.3372583709988252\n",
      "season \t 51.43172734035656\n",
      "yr \t 68.9565433348504\n",
      "mnth \t 0.0\n",
      "hr \t 146.2126971051315\n",
      "holiday \t -0.0\n",
      "weekday \t 0.0\n",
      "workingday \t 38.30510097122085\n",
      "weathersit \t -0.0\n",
      "temp \t 115.682864388095\n",
      "atemp \t 40.82193204642952\n",
      "hum \t -123.60515918120396\n",
      "windspeed \t 0.0\n",
      "\n",
      "alpha: 0.2\n",
      "R2 score: 0.3397512252932096\n",
      "season \t 53.327034965170434\n",
      "yr \t 69.99539206397505\n",
      "mnth \t 0.0\n",
      "hr \t 147.44979401570717\n",
      "holiday \t -0.0\n",
      "weekday \t 1.6155881949577173\n",
      "workingday \t 39.59279584817247\n",
      "weathersit \t -4.393396287320516\n",
      "temp \t 50.536611161421845\n",
      "atemp \t 124.02925347036496\n",
      "hum \t -127.61529270633936\n",
      "windspeed \t 11.643614632563553\n",
      "\n",
      "alpha: 0.1\n",
      "R2 score: 0.34049016925822095\n",
      "season \t 53.32487940523828\n",
      "yr \t 70.36185840048024\n",
      "mnth \t 0.9928328506782911\n",
      "hr \t 147.79247481689308\n",
      "holiday \t -1.3114906367495487\n",
      "weekday \t 2.480098498543455\n",
      "workingday \t 39.91029699568696\n",
      "weathersit \t -6.213745656254039\n",
      "temp \t 27.05884511668808\n",
      "atemp \t 153.97093277602715\n",
      "hum \t -128.47221598173022\n",
      "windspeed \t 17.362803023359966\n"
     ]
    }
   ],
   "source": [
    "for alpha in [1.0, 0.5, 0.2, 0.1]:\n",
    "    lasso = linear_model.Lasso(alpha = alpha)\n",
    "    lasso.fit(x1_train, y_train)\n",
    "    print('\\nalpha:', alpha)\n",
    "    print('R2 score:', lasso.score(x1_test, y_test))\n",
    "    for i in range(len(selected_cols)):\n",
    "        print(selected_cols[i], '\\t', lasso.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, no.<br/>\n",
    "Now let's consider the column 'weekday'. Although it is a numerical column, the numbers does not have a quantitative meaning, they are just indicators. Such columns are called **Nominal** columns, i.e., for each value x in the column 'weekday', we create a column called 'weekday=x', a record will get a value of 1 on this column if its orginal value is x, otherwise 0.<br/>\n",
    "pandas conviniently provides a function 'get_dummies' for this purpose.<br/>\n",
    "Both columns 'season' and 'weekday' are nominal columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = pd.get_dummies(bikes['season'], prefix = 'season_=')\n",
    "weekdays = pd.get_dummies(bikes['weekday'], prefix = 'weekday_=')\n",
    "\n",
    "bikes = pd.concat([bikes, seasons, weekdays], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting column is column 'weathersit'. The description tells us these four situations are very different.\n",
    "1. Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "2. Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "3. Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "4. Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "\n",
    "First, Situation 1 is mutually exclusive from the rest. Second, there is a degree of severity associated from situation 2 to 4, meaning if situation 3 happens, the weather has gone passed situation 2. This is so-called **ordinal** columns.<br/>\n",
    "For ordinal columns, we should turn on lower grade indicator automatically if the value is higher. For example, indicator for weathersit2 should be 1 all records with weathersit 2, 3, 4.<br/>\n",
    "Third, there are very few records for weathersit = 4, that we do not need to create one column just for weathersit 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution : 1-3 \n",
    "Season    :  4 Variables ; Weekday : 7 Variables and  weathersit : 3 variables\n",
    "Number of unique values in a columns determines number of dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['weathersit_=_1'] = 1 * (bikes['weathersit'] == 1)\n",
    "bikes['weathersit_>=_2'] = 1 * (bikes['weathersit'] >= 2)\n",
    "bikes['weathersit_>=_3'] = 1 * (bikes['weathersit'] >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['yr', 'mnth', 'hr', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed', 'season_=_1', 'season_=_2', 'season_=_3', 'season_=_4', 'weekday_=_0', 'weekday_=_1', 'weekday_=_2', 'weekday_=_3', 'weekday_=_4', 'weekday_=_5', 'weekday_=_6', 'weathersit_=_1', 'weathersit_>=_2', 'weathersit_>=_3']\n",
    "x2 = bikes[selected_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train, x2_test = x2[train,:], x2[~train,:]\n",
    "x2_train = min_max_scaler.fit_transform(x2_train)\n",
    "x2_test = min_max_scaler.transform(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1.0\n",
      "R2 score: 0.33921775613761235\n",
      "yr \t 67.24905214139518\n",
      "mnth \t 0.0\n",
      "hr \t 144.67172788492135\n",
      "holiday \t -0.0\n",
      "workingday \t 36.18694776794533\n",
      "temp \t 153.22080212218356\n",
      "atemp \t 0.0\n",
      "hum \t -100.8975043131971\n",
      "windspeed \t 0.0\n",
      "season_=_1 \t -22.862338921225902\n",
      "season_=_2 \t 0.0\n",
      "season_=_3 \t -0.0\n",
      "season_=_4 \t 29.9779373760094\n",
      "weekday_=_0 \t -0.36491197541835685\n",
      "weekday_=_1 \t -0.0\n",
      "weekday_=_2 \t 0.0\n",
      "weekday_=_3 \t 0.0\n",
      "weekday_=_4 \t 0.0\n",
      "weekday_=_5 \t -0.0\n",
      "weekday_=_6 \t 0.0\n",
      "weathersit_=_1 \t -0.0\n",
      "weathersit_>=_2 \t 0.0\n",
      "weathersit_>=_3 \t -20.931624064162538\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha = 1.0)\n",
    "lasso.fit(x2_train, y_train)\n",
    "print('alpha:', 1.0)\n",
    "print('R2 score:', lasso.score(x2_test, y_test))\n",
    "for i in range(len(selected_cols)):\n",
    "    print(selected_cols[i], '\\t', lasso.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, these indicator columns are not as significant as columns, 'yr', 'hr', 'workingday', 'temp' and 'hum'. Even with these five columns only, the performace is about the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1.0\n",
      "R2 score: 0.3185266344678772\n",
      "yr \t 67.08548284830512\n",
      "hr \t 144.23724453828655\n",
      "workingday \t 36.04793423065309\n",
      "temp \t 169.99315633922674\n",
      "hum \t -94.82501332221992\n"
     ]
    }
   ],
   "source": [
    "selected_cols = ['yr', 'hr', 'workingday', 'temp', 'hum']\n",
    "x3 = bikes[selected_cols].values\n",
    "x3_train, x3_test = x3[train,:], x3[~train,:]\n",
    "x3_train = min_max_scaler.fit_transform(x3_train)\n",
    "x3_test = min_max_scaler.transform(x3_test)\n",
    "lasso = linear_model.Lasso(alpha = 1.0)\n",
    "lasso.fit(x3_train, y_train)\n",
    "print('alpha:', 1.0)\n",
    "print('R2 score:', lasso.score(x3_test, y_test))\n",
    "for i in range(len(selected_cols)):\n",
    "    print(selected_cols[i], '\\t', lasso.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now think if there is a better way to use column 'dteday' since dates are not numerical values. We convert it to numerical values using data structure datetime with functions strptime and strftime.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1.0\n",
      "R2 score: 0.3283397490551171\n",
      "days \t 0 0.0\n",
      "yr \t 1 67.13944747006626\n",
      "mnth \t 2 41.30761282542185\n",
      "hr \t 3 143.2481965560545\n",
      "holiday \t 4 -0.0\n",
      "workingday \t 5 36.63245165956935\n",
      "temp \t 6 156.86655082776372\n",
      "atemp \t 7 0.0\n",
      "hum \t 8 -106.90584271067912\n",
      "windspeed \t 9 0.0\n"
     ]
    }
   ],
   "source": [
    "#days = np.zeros((num_row))\n",
    "#for i in range(num_row):\n",
    " #   days[i] = # using bikes.iloc[i]['dteday']\n",
    "##code\n",
    "num_row = len(bikes)\n",
    "days = np.zeros(num_row)\n",
    "for i in  range(num_row):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "    d = \"01\"\n",
    "    m = \"01\"\n",
    "    Current_date = datetime.strptime(bikes[\"dteday\"].iloc[i],date_format)\n",
    "    Current_date_year = Current_date.strftime(\"%Y\")\n",
    "    starting_Date = str(Current_date_year)+\"-\"+m+\"-\"+d\n",
    "    starting_Date_year = datetime.strptime(starting_Date ,date_format)\n",
    "    days[i] = abs(Current_date - starting_Date_year).days +1\n",
    "\n",
    "bikes['days'] = days\n",
    "\n",
    "\n",
    "selected_cols = ['days', 'yr', 'mnth', 'hr', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "x4 = bikes[selected_cols].values\n",
    "x4_train, x4_test = x4[train,:], x4[~train,:]\n",
    "x4_train = min_max_scaler.fit_transform(x4_train)\n",
    "x4_test = min_max_scaler.transform(x4_test)\n",
    "lasso = linear_model.Lasso(alpha = 1.0)\n",
    "lasso.fit(x4_train, y_train)\n",
    "print('alpha:', 1.0)\n",
    "print('R2 score:', lasso.score(x4_test, y_test))\n",
    "for i in range(len(selected_cols)):\n",
    "    print(selected_cols[i], '\\t',i, lasso.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak hour : Int64Index([17, 18, 8], dtype='int64', name='hr') \n"
     ]
    }
   ],
   "source": [
    "peak_hour = pd.DataFrame(bikes)[['hr','cnt']].groupby(\"hr\").sum().sort_values([\"cnt\"], ascending=False).index[0:3]\n",
    "print (\"peak hour : {} \".format(peak_hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak1 = 8\n",
    "peak2 = 17\n",
    "hr_diff = np.zeros((num_row,2))\n",
    "for i in  range(num_row):\n",
    "    hr_diff[i, 0] = min(abs(bikes.iloc[i]['hr'] - peak1), 24-abs(bikes.iloc[i]['hr']- peak1))\n",
    "    hr_diff[i, 1] = min(abs(bikes.iloc[i]['hr'] - peak2), 24-abs(bikes.iloc[i]['hr']- peak2))\n",
    "\n",
    "        \n",
    "bikes[\"hr_diff\"] = pd.DataFrame(hr_diff).min(axis = 1)\n",
    "\n",
    "month = pd.get_dummies(bikes['mnth'], prefix = 'mnth=')\n",
    "bikes = pd.concat([bikes,month], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared_Lesso Model - train:  0.45954604918682257 \n",
      "\n",
      "R-squared_Lesso Model - test :  0.4639772094131672 \n",
      "\n",
      "1. Coefficient : yr :  71.18852281248782\n",
      "\n",
      "2.Coefficient : hr_diff : -271.27861379847735\n",
      "\n",
      "3.Coefficient : temp : 139.65633015118158\n",
      "\n",
      "4.Coefficient : season_=_1 : -32.570848948573364\n",
      "\n",
      "5.Coefficient : mnth=_4 : -3.0076040364509455\n",
      "\n",
      "6.Coefficient : weathersit_=_1 : 19.111790458249065\n"
     ]
    }
   ],
   "source": [
    "selected_cols = ['yr','hr_diff','temp','season_=_1','mnth=_4','weathersit_=_1']\n",
    "\n",
    "x5 = bikes[selected_cols].values\n",
    "x5_train, x5_test = x5[train,:], x5[~train,:]\n",
    "x5_train = min_max_scaler.fit_transform(x5_train)\n",
    "x5_test = min_max_scaler.transform(x5_test)\n",
    "\n",
    "reg1 = linear_model.Lasso(alpha = 1)\n",
    "reg1.fit(x5_train, y_train)\n",
    "\n",
    "print(\"\\nR-squared_Lesso Model - train:  {} \".format(reg1.score(x5_train, y_train)))\n",
    "print(\"\\nR-squared_Lesso Model - test :  {} \".format(reg1.score(x5_test, y_test)))\n",
    "\n",
    "print ( \"\\n1. Coefficient : {} :  {}\".format(bikes[selected_cols].columns[0],reg1.coef_[0]))\n",
    "print ( \"\\n2.Coefficient : {} : {}\".format(bikes[selected_cols].columns[1],reg1.coef_[1]))\n",
    "print ( \"\\n3.Coefficient : {} : {}\".format(bikes[selected_cols].columns[2],reg1.coef_[2]))\n",
    "print ( \"\\n4.Coefficient : {} : {}\".format(bikes[selected_cols].columns[3],reg1.coef_[3]))\n",
    "print ( \"\\n5.Coefficient : {} : {}\".format(bikes[selected_cols].columns[4],reg1.coef_[4]))\n",
    "print ( \"\\n6.Coefficient : {} : {}\".format(bikes[selected_cols].columns[5],reg1.coef_[5]))\n",
    "# build x5 as the cell above\n",
    "# build a regression model with x5_train after normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "bikes = pd.read_csv('bike_sharing.csv')\n",
    "num_row = bikes.shape[0]\n",
    "y = bikes['registered'].values\n",
    "y = np.array([1 if i <= 60 else 2 if i <= 180 else 3 for i in y])\n",
    "\n",
    "np.random.seed(2021)\n",
    "selection = np.random.choice(['train', 'test', 'rest'], num_row, replace = True, p = [0.01, 0.09, 0.9])\n",
    "y_train, y_test = y[selection == 'train'], y[selection == 'test']\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dummy variables creation \n",
    "\n",
    "cols = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "selected_cols = ['yr', 'mnth', 'hr', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "yr = pd.get_dummies(bikes['yr'], prefix = 'yr=')\n",
    "mnth = pd.get_dummies(bikes['mnth'], prefix = 'mnth=')\n",
    "hr = pd.get_dummies(bikes['hr'], prefix = 'hr=')\n",
    "holiday = pd.get_dummies(bikes['holiday'], prefix = 'holiday=')\n",
    "workingday = pd.get_dummies(bikes['workingday'], prefix = 'workingday=')\n",
    "#df_ = bikes[selected_cols]\n",
    "df_ = pd.concat([yr,mnth,hr,holiday,workingday], axis = 1)\n",
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (171, 42), y_train shape : (171,)\n",
      "x_test shape (1551, 42), y_test shape : (1551,)\n"
     ]
    }
   ],
   "source": [
    "#selected_cols = ['yr', 'mnth', 'hr', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed']\n",
    "'''Split Data : Train - Test '''\n",
    "\n",
    "x = df_.values\n",
    "x_train, x_test = x[selection == 'train',:], x[selection == 'test',:]\n",
    "\n",
    "## Data Scaling \n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(x_train)\n",
    "x_test = min_max_scaler.transform(x_test)\n",
    "print (\"x_train shape {}, y_train shape : {}\".format(x_train.shape,y_train.shape))\n",
    "print (\"x_test shape {}, y_test shape : {}\".format(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " At C : 1 \n",
      " R2 Test : 0.6641 , R2-Train : 0.8187 , log_loss_train : 0.63 , log_loss_test : 0.79 \n",
      "\n",
      "Confusion Matrix : \n",
      "                     Predicted Class 1  Predicted Class 2  Predicted Class 3\n",
      "Predicted Class 1                398                 96                 21\n",
      "Predicted Class 2                 97                265                150\n",
      "Predicted Class 3                 13                144                367\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.77      0.78       515\n",
      "           2       0.52      0.52      0.52       512\n",
      "           3       0.68      0.70      0.69       524\n",
      "\n",
      "    accuracy                           0.66      1551\n",
      "   macro avg       0.66      0.66      0.66      1551\n",
      "weighted avg       0.66      0.66      0.66      1551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "num_C = 1\n",
    "\n",
    "logit = [None] * num_C\n",
    "inv_log_likelihood_train = [0.0] * num_C\n",
    "inv_log_likelihood_test = [0.0] * num_C\n",
    "\n",
    "R2_Test = []\n",
    "R2_Train = []\n",
    "inv_log_likelihood_train = []\n",
    "inv_log_likelihood_test = []\n",
    "\n",
    "for i in range(1,num_C+1):\n",
    "    #logicReg = LogisticRegression(C=i,random_state=12,solver ='newton-cg', multi_class = 'multinomial')\n",
    "    logicReg = LogisticRegression(C=i, random_state=12,solver ='newton-cg', multi_class = 'ovr')\n",
    "    logicReg.fit(x_train, y_train)\n",
    "    \n",
    "    R2Train = logicReg.score(x_train, y_train)\n",
    "    R2Test = logicReg.score(x_test, y_test)\n",
    "    \n",
    "    R2_Test.append(R2Test)\n",
    "    R2_Train.append(R2Train)\n",
    "    train_predict_probbility = logicReg.predict_proba(x_train)\n",
    "    test_predict_probbility = logicReg.predict_proba(x_test)  \n",
    "    \n",
    "    log_loss_train = log_loss(y_train, train_predict_probbility,eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "    log_loss_test = log_loss(y_test, test_predict_probbility,eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "    \n",
    "    inv_log_likelihood_train.append(log_loss_train)\n",
    "    inv_log_likelihood_test.append(log_loss_test)\n",
    "    \n",
    "print (\"\\n At C : {} \\n R2 Test : {:.4f} , R2-Train : {:.4f} , log_loss_train : {:.2f} , log_loss_test : {:.2f} \".format(i,R2Test,R2Train,log_loss_train,log_loss_test))\n",
    "col = [\"Predicted Class 1\",\"Predicted Class 2\",\"Predicted Class 3\"]\n",
    "print(\"\\nConfusion Matrix : \\n  {}\".format(pd.DataFrame(confusion_matrix(y_test,logicReg.predict(x_test)), columns = col, index =col)))\n",
    "\n",
    "print(\"\\nClassification report:\\n {}\".format(classification_report(y_test,logicReg.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At C : 0 ,R2 Test : 0.3320 ,R2-Train : 0.3567 ,inv_log_likelihood_train : 1.09 , inv_log_likelihood_test : 1.10 \n",
      "At C : 1 ,R2 Test : 0.4945 ,R2-Train : 0.5848 ,inv_log_likelihood_train : 1.06 , inv_log_likelihood_test : 1.07 \n",
      "At C : 2 ,R2 Test : 0.6022 ,R2-Train : 0.7310 ,inv_log_likelihood_train : 0.89 , inv_log_likelihood_test : 0.95 \n",
      "At C : 3 ,R2 Test : 0.6634 ,R2-Train : 0.8070 ,inv_log_likelihood_train : 0.57 , inv_log_likelihood_test : 0.76 \n",
      "At C : 4 ,R2 Test : 0.6770 ,R2-Train : 0.8363 ,inv_log_likelihood_train : 0.39 , inv_log_likelihood_test : 0.82 \n",
      "At C : 5 ,R2 Test : 0.6718 ,R2-Train : 0.8421 ,inv_log_likelihood_train : 0.34 , inv_log_likelihood_test : 1.07 \n",
      "At C : 6 ,R2 Test : 0.6744 ,R2-Train : 0.8421 ,inv_log_likelihood_train : 0.34 , inv_log_likelihood_test : 1.32 \n",
      "At C : 7 ,R2 Test : 0.6763 ,R2-Train : 0.8421 ,inv_log_likelihood_train : 0.33 , inv_log_likelihood_test : 1.52 \n",
      "At C : 8 ,R2 Test : 0.6763 ,R2-Train : 0.8421 ,inv_log_likelihood_train : 0.33 , inv_log_likelihood_test : 1.70 \n",
      "At C : 9 ,R2 Test : 0.6763 ,R2-Train : 0.8421 ,inv_log_likelihood_train : 0.33 , inv_log_likelihood_test : 1.85 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "num_C = 10\n",
    "C = [1.0] * num_C\n",
    "for i in range(num_C):\n",
    "    C[i] = pow(10, i-3)\n",
    "\n",
    "logit = [None] * num_C\n",
    "inv_log_likelihood_train = [0.0] * num_C\n",
    "inv_log_likelihood_test = [0.0] * num_C\n",
    "\n",
    "R2_Test = []\n",
    "R2_Train = []\n",
    "inv_log_likelihood_train = []\n",
    "inv_log_likelihood_test = []\n",
    "\n",
    "for i in range(num_C):\n",
    "    logicReg = LogisticRegression(C=C[i],random_state=12,solver ='newton-cg', multi_class = 'multinomial')\n",
    "    logicReg.fit(x_train, y_train)\n",
    "    \n",
    "    R2Train = logicReg.score(x_train, y_train)\n",
    "    R2Test = logicReg.score(x_test, y_test)\n",
    "    \n",
    "    R2_Test.append(R2Test)\n",
    "    R2_Train.append(R2Train)\n",
    "    train_predict_probbility = logicReg.predict_proba(x_train)\n",
    "    test_predict_probbility = logicReg.predict_proba(x_test)  \n",
    "    \n",
    "    log_loss_train = log_loss(y_train,train_predict_probbility,eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "    log_loss_test = log_loss(y_test,test_predict_probbility,eps=1e-15, normalize=True, sample_weight=None, labels=None)\n",
    "    \n",
    "    inv_log_likelihood_train.append(log_loss_train)\n",
    "    inv_log_likelihood_test.append(log_loss_test)\n",
    "    \n",
    "    print (\"At C : {} ,R2 Test : {:.4f} ,R2-Train : {:.4f} ,inv_log_likelihood_train : {:.2f} , inv_log_likelihood_test : {:.2f} \".format(i,R2Test,R2Train,log_loss_train,log_loss_test))\n",
    "\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.xscale('log')\n",
    "plt.plot(C, inv_log_likelihood_train, 'bo-', C, inv_log_likelihood_test, 'ro-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
